# Movies-ETL

1.	  PURPOSE OF THE ANALYSIS
  
In this module, you'll learn how to use the Extract, Transform, Load (ETL) process to create data pipelines. A data pipeline moves data from a source to a destination, and the ETL process creates data pipelines that also transform the data along the way. Analysis is impossible without access to good data, so creating data pipelines is often the first step before any analysis can be performed. Therefore, understanding ETL is an essential skill for data analysis as highlighted below:

•	Create an ETL pipeline from raw data to a SQL database.
•	Extract data from disparate sources using Python.
•	Clean and transform data using Pandas.
•	Use regular expressions to parse data and to transform text into numbers.
•	Load data with PostgreSQL.


2.	  SOFTWARE/MATERIALS USED
	  
      •	PostgresSQL 14

      •	Python 3.7.6

      •	 Jupyter Notebook 3.7.13

3.	  CHALLENGES/EXPERIENCE GARNERED
	  
In this module, we learned how to use the Extract, Transform, Load (ETL) process to create data pipelines. A data pipeline moves data from a source to a destination, and the ETL process creates data pipelines that also transform the data along the way.
In this module, we also produced a function for loading Wikipedia, Kaggle and Movie lens data into a SQL database.
